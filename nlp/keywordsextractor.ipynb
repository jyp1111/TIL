{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keywordsextractor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPz7lIRT90hIwsmKU+1U4pw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyp1111/TIL/blob/master/nlp/keywordsextractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahsaJdUkU3aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from itertools import permutations\n",
        "import numpy as np\n",
        "from konlpy.tag import Okt\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy6NMKfVUs6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class textrank:    \n",
        "    def __init__(self,word_ls):\n",
        "        self.word_ls=word_ls\n",
        "    def connected_matrix(self,windows_size):\n",
        "        L_unique=list(set(self.word_ls))\n",
        "        n=len(L_unique)\n",
        "        Mat=np.zeros((n,n))\n",
        "\n",
        "        for i in range(len(self.word_ls)-(windows_size-1)):\n",
        "            for v in list(permutations(range(windows_size), 2)):\n",
        "                Mat[L_unique.index(self.word_ls[i:i+windows_size][v[0]])][L_unique.index(self.word_ls[i:i+windows_size][v[1]])]=1\n",
        "        for i,x in enumerate(Mat):\n",
        "            Mat[i]=Mat[i]/sum(Mat[i])\n",
        "        return Mat\n",
        "    def score(self,d,windows_size,num_epoch,threshold):\n",
        "        L_unique=list(set(self.word_ls))\n",
        "        score=np.ones(len(L_unique))\n",
        "        table=[]\n",
        "        for i in range(num_epoch):\n",
        "            new_score=(1-d)+np.dot(self.connected_matrix(windows_size).T,d*score)\n",
        "            if (np.abs(score-new_score)).mean()<threshold:\n",
        "                break\n",
        "            score=new_score\n",
        "        for i,x in enumerate(L_unique):\n",
        "            table.append({\"word\":x,\"score\":new_score[i]})\n",
        "        table=pd.DataFrame(table)\n",
        "        return table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76j6UnsQUwBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_ls(url):\n",
        "    res=requests.get(url)\n",
        "    soup=BeautifulSoup(res.text,\"html.parser\")\n",
        "    result=soup.select_one(\"#articleBodyContents\")\n",
        "    result_text=result.text.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\"function _flash_removeCallback() {}\",\"\").replace(\"// flash 오류를 우회하기 위한 함수 추가\",\"\")\n",
        "    for x in result.select(\"a\"):\n",
        "        result_text=result_text.replace(x.text,\"\")\n",
        "    result_text=result_text.replace(\"▶\",\"\")\n",
        "    result_text=result_text.replace(\"무단 전재 및 재배포 금지\",\"\")\n",
        "    \n",
        "    okt= Okt()\n",
        "    okt_tokens = okt.morphs(result_text)\n",
        "    oktTag = []\n",
        "    for token in okt_tokens:\n",
        "        oktTag += okt.pos(token)\n",
        "    stopPos=[\"Punctuation\",\"Josa\",\"Foreign\",\"Adverb\",\"URL\",\"Verb\",\"Conjunction\"]\n",
        "\n",
        "    keyword = []\n",
        "    for tag in oktTag:\n",
        "        if tag[1] not in stopPos:\n",
        "            if len(tag[0])>1:      \n",
        "                keyword.append(tag[0])\n",
        "    word = []\n",
        "    for tag in oktTag:\n",
        "        if tag[1] not in stopPos:     \n",
        "                word.append(tag[0])\n",
        "\n",
        "    words=[]\n",
        "    temp_ls=[]\n",
        "    for i,tag in enumerate(oktTag):\n",
        "        if tag[1] in stopPos:\n",
        "            if len(temp_ls)>0:\n",
        "                words.append(temp_ls)\n",
        "            temp_ls=[]\n",
        "        else:\n",
        "            temp_ls.append(tag[0])\n",
        "            if i==len(oktTag)-1:\n",
        "                words.append(temp_ls)\n",
        "\n",
        "    return keyword,word,words\n",
        "\n",
        "def keyword_recommand(url,num,d,windows_size,num_epoch,threshold):\n",
        "    keyword,_,_=word_ls(url)\n",
        "    table=textrank(keyword).score(d,windows_size,num_epoch,threshold).sort_values(by=\"score\",ascending=False)\n",
        "    return table.head(num)[\"word\"].tolist()\n",
        "def words_recommand(url,num,d,windows_size,num_epoch,threshold):\n",
        "    _,word,words=word_ls(url)\n",
        "    word_uniqe_list=list(set(word))\n",
        "    temp_ls=[]\n",
        "\n",
        "    for x in word_uniqe_list:\n",
        "        for j in range(len(words)):\n",
        "            if x in words[j]:\n",
        "                temp_ls.append({\"word\":x,\"words_cat\":j})\n",
        "    temp_table=pd.DataFrame(temp_ls)\n",
        "    score_table=textrank(word).score(d,windows_size,num_epoch,threshold)\n",
        "    table=temp_table.merge(score_table,how=\"left\",on=\"word\").pivot_table(index=\"words_cat\",values=\"score\",aggfunc=\"sum\").sort_values(by=\"score\",ascending=False)\n",
        "    return [words[i] for i in table.head(5).index.tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGXBawZ4VnK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class tf_idf:\n",
        "    def __init__(self,docs):\n",
        "        self.docs=docs\n",
        "        \n",
        "    def make_data(self):   \n",
        "        word_list=[x[1] for x in enumerate(list(tf_idf.doc_union))]\n",
        "        data=pd.DataFrame(word_list)\n",
        "        data.columns=[\"word\"]\n",
        "        return data\n",
        "\n",
        "    def freq(self,word,i):\n",
        "        count=0\n",
        "        for x in tf_idf.doc_token_list[i]:\n",
        "            if x==word:\n",
        "                count+=1\n",
        "        return count\n",
        "\n",
        "    def make_df_data(self,d):\n",
        "        i=tf_idf.doc_list.index(d)\n",
        "        data_df=self.make_data().copy()\n",
        "        data_df[\"freq\"]=self.make_data()[\"word\"].apply(self.freq, args=(i,))\n",
        "        data_df[\"totalfreq\"]=len(tf_idf.doc_token_list[i])\n",
        "        data_df[\"tf\"]=data_df[\"freq\"]/data_df[\"totalfreq\"]\n",
        "\n",
        "        return data_df\n",
        "\n",
        "    def idf_freq(self,row):\n",
        "        count=0\n",
        "        for x in tf_idf.doc_token_list:\n",
        "            count+=int(row[\"word\"] in x)\n",
        "        return count\n",
        "    def make_idf_data(self):\n",
        "        data_idf=self.make_data().copy()\n",
        "        data_idf[\"total_count\"]=tf_idf.doc_count\n",
        "        data_idf[\"count\"]=data_idf.apply(self.idf_freq,axis=1)\n",
        "        data_idf[\"idf\"]=-np.log(data_idf[\"count\"]/data_idf[\"total_count\"])\n",
        "        return data_idf\n",
        "    def result_table(self,d):\n",
        "        i=tf_idf.doc_list.index(d)\n",
        "        doc=self.make_df_data(d).merge(self.make_idf_data(),how=\"inner\",on=\"word\")[[\"word\",\"tf\",\"idf\"]]\n",
        "        doc[\"tf-idf\"]=doc[\"tf\"]*doc[\"idf\"]\n",
        "        return doc"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}